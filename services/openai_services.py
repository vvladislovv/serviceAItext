from openai import OpenAI
from config.config import get_config
import time
import json
import requests
from services.logging import logs_bot
from Messages.settingsmsg import new_message, update_message, send_typing_action
from Messages.utils import download_voice_user, escape_markdown
from database.settingsdata import get_user_history, save_chat_history
from typing import Optional, Tuple, List, Dict, Any
from dataclasses import dataclass
import os

config = get_config()
last_messages = {}

@dataclass
class MessageResponse:
    """–°—Ç—Ä—É–∫—Ç—É—Ä–∞ –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –æ—Ç–≤–µ—Ç–∞ –∏ —Å–æ–æ–±—â–µ–Ω–∏—è"""
    response: str
    message: object

class OpenAIService:
    def __init__(self):
        self.client = OpenAI(
            api_key=config.openai.api_key,
            base_url=config.openai.base_url
        )
        self.default_system_message = "–¢—ã –ø–æ–ª–µ–∑–Ω—ã–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç, –∫–æ—Ç–æ—Ä—ã–π –ø–æ–º–Ω–∏—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç —Ä–∞–∑–≥–æ–≤–æ—Ä–∞."
        # –ë–∞–∑–æ–≤—ã–µ URL –¥–ª—è —Ä–∞–∑–Ω—ã—Ö –ø—Ä–æ–≤–∞–π–¥–µ—Ä–æ–≤ ProxyAPI
        self.proxy_base_urls = {
            "openai": "https://api.proxyapi.ru/openai",
            "anthropic": "https://api.proxyapi.ru/anthropic",
            "google": "https://api.proxyapi.ru/google",
            "deepseek": "https://api.proxyapi.ru/deepseek"
        }
        

    async def _make_api_request(self, api_func, *args, **kwargs) -> Optional[str]:
        """–û–±—â–∏–π –æ–±—Ä–∞–±–æ—Ç—á–∏–∫ API –∑–∞–ø—Ä–æ—Å–æ–≤ —Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –æ—à–∏–±–æ–∫"""
        try:
            return await api_func(*args, **kwargs)
        except Exception as e:
            error_msg = f"Error in {api_func.__name__}: {str(e)}"
            await logs_bot("error", error_msg)
            return None

    async def _make_proxy_request(self, provider: str, endpoint: str, data: Dict[str, Any]) -> Optional[Dict[str, Any]]:
        """–í—ã–ø–æ–ª–Ω—è–µ—Ç –∑–∞–ø—Ä–æ—Å –∫ ProxyAPI"""
        try:
            base_url = self.proxy_base_urls.get(provider)
            if not base_url:
                await logs_bot("error", f"Unknown provider: {provider}")
                return None
                
            url = f"{base_url}{endpoint}"
            headers = {
                "Content-Type": "application/json",
                "Authorization": f"Bearer {self.client.api_key}"
            }
            
            # –î–ª—è Anthropic –¥–æ–±–∞–≤–ª—è–µ–º —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–π –∑–∞–≥–æ–ª–æ–≤–æ–∫
            if provider == "anthropic":
                headers["Anthropic-Version"] = "2023-06-01"
                
            await logs_bot("debug", f"Making request to {url}")
            response = requests.post(url, headers=headers, json=data, timeout=60)
            
            if response.status_code != 200:
                await logs_bot("error", f"ProxyAPI error: {response.status_code} - {response.text}")
                return None
                
            return response.json()
        except Exception as e:
            await logs_bot("error", f"Error in _make_proxy_request: {str(e)}")
            return None
        

    async def text_to_speech(self, text: str, voice: str = "alloy", model: str = "tts") -> Optional[str]:
        """
        –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –≤ —Ä–µ—á—å
        
        Args:
            text: –¢–µ–∫—Å—Ç –¥–ª—è –æ–∑–≤—É—á–∏–≤–∞–Ω–∏—è
            voice: –ì–æ–ª–æ—Å (alloy, echo, fable, onyx, nova, shimmer)
            model: –ú–æ–¥–µ–ª—å TTS (tts –∏–ª–∏ tts_hd)
            
        Returns:
            Optional[str]: –ü—É—Ç—å –∫ —Å–æ–∑–¥–∞–Ω–Ω–æ–º—É –∞—É–¥–∏–æ—Ñ–∞–π–ª—É –∏–ª–∏ None –≤ —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏
        """
        try:
            # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –º–æ–¥–µ–ª—å
            tts_model = "tts-1-hd" if model == "tts_hd" else "tts-1"
            
            await logs_bot("debug", f"Starting TTS generation with model: {tts_model}, voice: {voice}")
            
            # –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –¥–ª—è –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤, –µ—Å–ª–∏ –µ—ë –Ω–µ—Ç
            os.makedirs("temp", exist_ok=True)
            
            # –î–ª—è —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–≥–æ OpenAI API
            if self.client.base_url == "https://api.openai.com/v1":
                response = self.client.audio.speech.create(
                    model=tts_model,
                    voice=voice,
                    input=text
                )
                
                if response:
                    speech_file_path = f"temp/speech_{voice}_{int(time.time())}.mp3"
                    response.stream_to_file(speech_file_path)
                    return speech_file_path
            else:
                # –î–ª—è ProxyAPI
                data = {
                    "model": tts_model,
                    "voice": voice,
                    "input": text
                }
                
                # –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –∑–∞–ø—Ä–æ—Å–∞ —á–µ—Ä–µ–∑ ProxyAPI
                await logs_bot("debug", f"Sending TTS request to ProxyAPI: {json.dumps(data)}")
                
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º requests –Ω–∞–ø—Ä—è–º—É—é –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –±–∏–Ω–∞—Ä–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
                url = f"{self.proxy_base_urls['openai']}/v1/audio/speech"
                headers = {
                    "Content-Type": "application/json",
                    "Authorization": f"Bearer {self.client.api_key}"
                }
                
                response = requests.post(url, headers=headers, json=data, timeout=60)
                
                if response.status_code == 200:
                    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∞—É–¥–∏–æ –≤–æ –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
                    speech_file_path = f"temp/speech_{voice}_{int(time.time())}.mp3"
                    with open(speech_file_path, "wb") as f:
                        f.write(response.content)
                    
                    await logs_bot("debug", f"TTS file saved to {speech_file_path}")
                    return speech_file_path
                else:
                    await logs_bot("error", f"ProxyAPI error: {response.status_code} - {response.text}")
            
            await logs_bot("warning", "Empty or invalid response from TTS API")
            return None
            
        except Exception as e:
            await logs_bot("error", f"Error in text_to_speech: {str(e)}")
            import traceback
            await logs_bot("error", traceback.format_exc())
            return None

    async def speech_to_text(self, audio_path: str, model: str = "whisper-1") -> str:
        """–ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –∞—É–¥–∏–æ –≤ —Ç–µ–∫—Å—Ç"""
        try:
            with open(audio_path, "rb") as audio_file:
                transcript = self.client.audio.transcriptions.create(
                    model=model,
                    file=audio_file
                )
                return transcript.text
        except Exception as e:
            await logs_bot("error", f"Error in speech_to_text: {str(e)}")
            return ""

    async def _prepare_messages(self, user_message: str, context: list, system_message: str = None):
        """–ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ—Ç —Å–ø–∏—Å–æ–∫ —Å–æ–æ–±—â–µ–Ω–∏–π –¥–ª—è OpenAI API —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º"""
        messages = []
        
        # –î–æ–±–∞–≤–ª—è–µ–º —Å–∏—Å—Ç–µ–º–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ, –µ—Å–ª–∏ –æ–Ω–æ –µ—Å—Ç—å
        if system_message:
            messages.append({
                "role": "system",
                "content": system_message
            })
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –∏ —è–≤–ª—è–µ—Ç—Å—è —Å–ø–∏—Å–∫–æ–º
        if context and isinstance(context, list):
            # –ë–µ—Ä–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ 5 –ø–∞—Ä —Å–æ–æ–±—â–µ–Ω–∏–π (–∏–ª–∏ –º–µ–Ω—å—à–µ, –µ—Å–ª–∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç –∫–æ—Ä–æ—á–µ)
            context_pairs = []
            
            # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –≤ –ø–∞—Ä—ã "–≤–æ–ø—Ä–æ—Å-–æ—Ç–≤–µ—Ç"
            i = 0
            while i < len(context) - 1 and len(context_pairs) < 5:
                user_msg = context[i]
                assistant_msg = context[i + 1]
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –æ–±–∞ —Å–æ–æ–±—â–µ–Ω–∏—è –Ω–µ –ø—É—Å—Ç—ã–µ
                if user_msg and assistant_msg:
                    context_pairs.append((user_msg, assistant_msg))
                
                i += 2
            
            # –î–æ–±–∞–≤–ª—è–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ 5 –ø–∞—Ä –≤ —Å–æ–æ–±—â–µ–Ω–∏—è
            for user_msg, assistant_msg in context_pairs[-5:]:
                messages.extend([
                    {"role": "user", "content": str(user_msg)},
                    {"role": "assistant", "content": str(assistant_msg)}
                ])
        
        # –î–æ–±–∞–≤–ª—è–µ–º —Ç–µ–∫—É—â–µ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        messages.append({"role": "user", "content": user_message})
        
        # –õ–æ–≥–∏—Ä—É–µ–º –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
        await logs_bot("debug", f"Prepared {len(messages)} messages for API")
        
        return messages

    async def chat_completion_with_context(self, user_message: str, context: list, model_gpt: str) -> str:
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ —Å–æ–æ–±—â–µ–Ω–∏—è —Å —É—á–µ—Ç–æ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞"""
        try:
            # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º —Å–æ–æ–±—â–µ–Ω–∏—è
            messages = await self._prepare_messages(
                user_message, 
                context,
                self.default_system_message
            )
            
            # –î–æ–±–∞–≤–ª—è–µ–º –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
            await logs_bot("debug", f"Sending request to API with model: {model_gpt}")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –º–æ–¥–µ–ª—å —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –∏ –¥–æ—Å—Ç—É–ø–Ω–∞
            if not model_gpt:
                await logs_bot("error", "Model name is empty or None")
                return "–û—à–∏–±–∫–∞: –Ω–µ —É–∫–∞–∑–∞–Ω–∞ –º–æ–¥–µ–ª—å AI\\."
            
            # –ú–∞—Ä—à—Ä—É—Ç–∏–∑–∞—Ü–∏—è –∑–∞–ø—Ä–æ—Å–æ–≤ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –º–æ–¥–µ–ª–∏
            if model_gpt in ["o1-mini", "o1", "o3mini"]:
                # –î–ª—è –º–æ–¥–µ–ª–µ–π O1 –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç
                return await self._process_o1(messages, model_gpt)
            elif model_gpt in ["claude-3-5-sonnet", "claude-3-haiku"]:
                # –î–ª—è –º–æ–¥–µ–ª–µ–π Claude –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç
                return await self._process_claude(messages, model_gpt)
            elif model_gpt in ["gemini-1.5-flash"]:
                # –î–ª—è –º–æ–¥–µ–ª–µ–π Gemini –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç
                return await self._process_gemini(messages, model_gpt)
            elif model_gpt in ["deepseek-v3", "deepseek-r1"]:
                # –î–ª—è –º–æ–¥–µ–ª–µ–π DeepSeek –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç
                return await self._process_deepseek(messages, model_gpt)
            else:
                # –î–ª—è –º–æ–¥–µ–ª–µ–π OpenAI –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç
                try:
                    response = self.client.chat.completions.create(
                        model=model_gpt,
                        messages=messages,
                    )
                except Exception as api_error:
                    await logs_bot("error", f"OpenAI API error: {str(api_error)}")
                    return f"–û—à–∏–±–∫–∞ API: {escape_markdown(str(api_error)[:100])}\\."
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ—Ç–≤–µ—Ç
                if response and response.choices and len(response.choices) > 0:
                    content = response.choices[0].message.content
                    return content
                
                # –ï—Å–ª–∏ –æ—Ç–≤–µ—Ç –ø—É—Å—Ç–æ–π –∏–ª–∏ –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π
                await logs_bot("warning", "Empty or invalid response from OpenAI")
                return "–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –æ—Ç–≤–µ—Ç –æ—Ç –º–æ–¥–µ–ª–∏\\."
                
        except Exception as e:
            # –ü–æ–¥—Ä–æ–±–Ω–æ–µ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –æ—à–∏–±–∫–∏
            error_details = f"Error details: {str(e)}\nModel: {model_gpt}"
            await logs_bot("error", f"Error in chat completion: {error_details}")
            return "–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∑–∞–ø—Ä–æ—Å–∞\\."

    async def _process_o1(self, messages: List[Dict[str, Any]], model: str) -> str:
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–ø—Ä–æ—Å–æ–≤ –∫ –º–æ–¥–µ–ª—è–º O1, O1-mini, O3-mini —á–µ—Ä–µ–∑ OpenAI API"""
        try:
            # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º —Å–æ–æ–±—â–µ–Ω–∏—è –≤ —Ñ–æ—Ä–º–∞—Ç, –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π –º–æ–¥–µ–ª—è–º–∏ O1
            processed_messages = []
            system_content = None
            
            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Å–∏—Å—Ç–µ–º–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
            for msg in messages:
                if msg["role"] == "system":
                    system_content = msg["content"]
                else:
                    processed_messages.append({
                        "role": msg["role"],
                        "content": msg["content"]
                    })
            
            # –ï—Å–ª–∏ –µ—Å—Ç—å —Å–∏—Å—Ç–µ–º–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ, –¥–æ–±–∞–≤–ª—è–µ–º –µ–≥–æ –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç
            if system_content:
                # –î–ª—è –ø–µ—Ä–≤–æ–≥–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è –¥–æ–±–∞–≤–ª—è–µ–º —Å–∏—Å—Ç–µ–º–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç
                if processed_messages and processed_messages[0]["role"] == "user":
                    processed_messages[0]["content"] = f"–ö–æ–Ω—Ç–µ–∫—Å—Ç: {system_content}\n\n{processed_messages[0]['content']}"
                else:
                    # –ï—Å–ª–∏ –Ω–µ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏—Ö —Å–æ–æ–±—â–µ–Ω–∏–π, —Å–æ–∑–¥–∞–µ–º –Ω–æ–≤–æ–µ
                    processed_messages.insert(0, {
                        "role": "user",
                        "content": f"–ö–æ–Ω—Ç–µ–∫—Å—Ç: {system_content}"
                    })
            
            # –í—ã–ø–æ–ª–Ω—è–µ–º –∑–∞–ø—Ä–æ—Å –∫ API
            response = self.client.chat.completions.create(
                model=model,
                messages=processed_messages,
            )
            
            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –æ—Ç–≤–µ—Ç
            if response and response.choices and len(response.choices) > 0:
                return response.choices[0].message.content
            
            await logs_bot("warning", f"Empty or invalid response from {model}")
            return f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –æ—Ç–≤–µ—Ç –æ—Ç –º–æ–¥–µ–ª–∏ {model}\\."
            
        except Exception as e:
            await logs_bot("error", f"Error in _process_o1 for {model}: {str(e)}")
            return f"–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∑–∞–ø—Ä–æ—Å–∞ {model}\\."

    async def _process_deepseek(self, messages: List[Dict[str, Any]], model: str) -> str:
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–ø—Ä–æ—Å–æ–≤ –∫ DeepSeek –º–æ–¥–µ–ª—è–º"""
        try:
            # –ú–∞–ø–ø–∏–Ω–≥ –º–æ–¥–µ–ª–µ–π
            model_mapping = {
                "deepseek-v3": "deepseek-chat",
                "deepseek-r1": "deepseek-chat"
            }
            
            deepseek_model = model_mapping.get(model, "deepseek-chat")
            
            # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞
            data = {
                "model": deepseek_model,
                "messages": messages
            }
            
            # –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –∑–∞–ø—Ä–æ—Å–∞
            response = await self._make_proxy_request("deepseek", "/chat/completions", data)
            
            if response and "choices" in response and len(response["choices"]) > 0:
                return response["choices"][0]["message"]["content"]
            
            await logs_bot("warning", f"Empty or invalid response from DeepSeek: {response}")
            return "–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –æ—Ç–≤–µ—Ç –æ—Ç –º–æ–¥–µ–ª–∏ DeepSeek\\."
            
        except Exception as e:
            await logs_bot("error", f"Error in _process_deepseek: {str(e)}")
            return "–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∑–∞–ø—Ä–æ—Å–∞ DeepSeek\\."

    async def _process_claude(self, messages: List[Dict[str, Any]], model: str) -> str:
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–ø—Ä–æ—Å–æ–≤ –∫ Claude –º–æ–¥–µ–ª—è–º"""
        try:
            # –ú–∞–ø–ø–∏–Ω–≥ –º–æ–¥–µ–ª–µ–π
            model_mapping = {
                "claude-3-5-sonnet": "claude-3-5-sonnet-20241022",
                "claude-3-haiku": "claude-3-haiku-20240307"
            }
            
            claude_model = model_mapping.get(model, model)
            
            # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º —Å–æ–æ–±—â–µ–Ω–∏—è –≤ —Ñ–æ—Ä–º–∞—Ç Claude
            claude_messages = []
            for msg in messages:
                if msg["role"] != "system":  # –°–∏—Å—Ç–µ–º–Ω—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—é—Ç—Å—è –æ—Ç–¥–µ–ª—å–Ω–æ
                    claude_messages.append({
                        "role": msg["role"],
                        "content": msg["content"]
                    })
            
            # –ù–∞—Ö–æ–¥–∏–º —Å–∏—Å—Ç–µ–º–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
            system_content = next((msg["content"] for msg in messages if msg["role"] == "system"), None)
            
            # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞
            data = {
                "model": claude_model,
                "messages": claude_messages,
                "max_tokens": 1024
            }
            
            # –î–æ–±–∞–≤–ª—è–µ–º —Å–∏—Å—Ç–µ–º–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ, –µ—Å–ª–∏ –æ–Ω–æ –µ—Å—Ç—å
            if system_content:
                data["system"] = system_content
            
            # –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –∑–∞–ø—Ä–æ—Å–∞
            response = await self._make_proxy_request("anthropic", "/v1/messages", data)
            
            if response and "content" in response and len(response["content"]) > 0:
                # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–∫—Å—Ç –∏–∑ –æ—Ç–≤–µ—Ç–∞
                for content_item in response["content"]:
                    if content_item["type"] == "text":
                        return content_item["text"]
            
            await logs_bot("warning", f"Empty or invalid response from Claude: {response}")
            return "–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –æ—Ç–≤–µ—Ç –æ—Ç –º–æ–¥–µ–ª–∏ Claude\\."
            
        except Exception as e:
            await logs_bot("error", f"Error in _process_claude: {str(e)}")
            return "–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∑–∞–ø—Ä–æ—Å–∞ Claude\\."

    async def _process_gemini(self, messages: List[Dict[str, Any]], model: str) -> str:
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–ø—Ä–æ—Å–æ–≤ –∫ Gemini –º–æ–¥–µ–ª—è–º"""
        try:
            # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º —Å–æ–æ–±—â–µ–Ω–∏—è –≤ —Ñ–æ—Ä–º–∞—Ç Gemini
            gemini_contents = []
            
            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Å–∏—Å—Ç–µ–º–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
            system_content = next((msg["content"] for msg in messages if msg["role"] == "system"), None)
            
            # –ï—Å–ª–∏ –µ—Å—Ç—å —Å–∏—Å—Ç–µ–º–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ, –¥–æ–±–∞–≤–ª—è–µ–º –µ–≥–æ –∫–∞–∫ —Å–æ–æ–±—â–µ–Ω–∏–µ –æ—Ç –º–æ–¥–µ–ª–∏
            if system_content:
                gemini_contents.append({
                    "role": "model",
                    "parts": [{"text": system_content}]
                })
            
            # –î–æ–±–∞–≤–ª—è–µ–º –æ—Å—Ç–∞–ª—å–Ω—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è
            for msg in messages:
                if msg["role"] != "system":  # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Å–∏—Å—Ç–µ–º–Ω—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è, –æ–Ω–∏ —É–∂–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω—ã
                    role = "user" if msg["role"] == "user" else "model"
                    gemini_contents.append({
                        "role": role,
                        "parts": [{"text": msg["content"]}]
                    })
            
            # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞
            data = {
                "contents": gemini_contents
            }
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —ç–Ω–¥–ø–æ–∏–Ω—Ç –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –º–æ–¥–µ–ª–∏
            endpoint = f"/v1/models/{model}:generateContent"
            
            # –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –∑–∞–ø—Ä–æ—Å–∞
            response = await self._make_proxy_request("google", endpoint, data)
            
            if response and "candidates" in response and len(response["candidates"]) > 0:
                candidate = response["candidates"][0]
                if "content" in candidate and "parts" in candidate["content"]:
                    parts = candidate["content"]["parts"]
                    if len(parts) > 0 and "text" in parts[0]:
                        return parts[0]["text"]
            
            await logs_bot("warning", f"Empty or invalid response from Gemini: {response}")
            return "–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –æ—Ç–≤–µ—Ç –æ—Ç –º–æ–¥–µ–ª–∏ Gemini\\."
            
        except Exception as e:
            await logs_bot("error", f"Error in _process_gemini: {str(e)}")
            return "–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∑–∞–ø—Ä–æ—Å–∞ Gemini\\."

async def AI_choice(message, model: str) -> Tuple[str, object]:
    """–û—Å–Ω–æ–≤–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç—á–∏–∫ —Å–æ–æ–±—â–µ–Ω–∏–π"""
    message_text = None
    await send_typing_action(message)
    # –û–±—Ä–∞–±–æ—Ç–∫–∞ –ø—Ä–µ–¥—ã–¥—É—â–µ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è
    if message.from_user.id in last_messages:
        try:
            old_message, old_text = last_messages[message.from_user.id]
            await update_message(old_message, old_text, None)
        except Exception as e:
            await logs_bot('error', f"Error removing keyboard: {e}")

    # –°–æ–∑–¥–∞–Ω–∏–µ —Å–æ–æ–±—â–µ–Ω–∏—è –æ –ø—Ä–æ—Ü–µ—Å—Å–µ
    model_display_name = escape_markdown(model)  # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ñ—É–Ω–∫—Ü–∏—é escape_markdown
    processing_text = f"ü§ñ *{model_display_name}* –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –≤–∞—à –∑–∞–ø—Ä–æ—Å\\.\\.\\."
    msg_old = await new_message(message, processing_text, None)

    try:
        # –û–±—Ä–∞–±–æ—Ç–∫–∞ –≤—Ö–æ–¥—è—â–µ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è
        if message.voice:
            audio_file_path = await download_voice_user(message)
            message_text = await openai_service.speech_to_text(audio_file_path, "whisper-1")
        elif message.text:
            message_text = message.text

        if not message_text:
            return "–ù–µ —É–¥–∞–ª–æ—Å—å –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å —Å–æ–æ–±—â–µ–Ω–∏–µ\\.", msg_old

        # –ü–æ–ª—É—á–µ–Ω–∏–µ –∏—Å—Ç–æ—Ä–∏–∏ –∏ –æ–±—Ä–∞–±–æ—Ç–∫–∞ –º–æ–¥–µ–ª–∏
        history = await get_user_history(message.from_user.id, 5)
        
        # –ü–æ–ª—É—á–µ–Ω–∏–µ –æ—Ç–≤–µ—Ç–∞ –æ—Ç –º–æ–¥–µ–ª–∏ —á–µ—Ä–µ–∑ —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π –æ–±—Ä–∞–±–æ—Ç—á–∏–∫
        response = await openai_service.chat_completion_with_context(
            message_text,
            history,
            model
        )

        # –û—á–∏—â–∞–µ–º –æ—Ç–≤–µ—Ç –æ—Ç —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö –¥–µ—Ç–∞–ª–µ–π, –µ—Å–ª–∏ –æ–Ω–∏ –µ—Å—Ç—å
        if response and isinstance(response, str):
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ –Ω–∞–ª–∏—á–∏–µ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö –¥–µ—Ç–∞–ª–µ–π
            if "{'role':" in response or '{"role":' in response:
                try:
                    # –ü—Ä–æ—Å—Ç–∞—è –æ—á–∏—Å—Ç–∫–∞ –±–µ–∑ —Ä–µ–≥—É–ª—è—Ä–Ω—ã—Ö –≤—ã—Ä–∞–∂–µ–Ω–∏–π
                    content_start = response.find("'content': '")
                    if content_start == -1:
                        content_start = response.find('"content": "')
                    
                    if content_start != -1:
                        content_start = response.find("'", content_start + 11)
                        if content_start == -1:
                            content_start = response.find('"', content_start + 11)
                        
                        content_end = response.rfind("'}")
                        if content_end == -1:
                            content_end = response.rfind('"')
                        
                        if content_start != -1 and content_end != -1:
                            response = response[content_start+1:content_end]
                            await logs_bot("debug", "Cleaned technical details from response")
                except Exception as e:
                    await logs_bot("warning", f"Failed to clean response: {e}")

        if response:
            # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
            try:
                # –ü–æ–ª—É—á–∞–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π –∫–æ–Ω—Ç–µ–∫—Å—Ç
                existing_context = []
                if history:
                    existing_context = history
                
                # –î–æ–±–∞–≤–ª—è–µ–º –Ω–æ–≤—É—é –ø–∞—Ä—É —Å–æ–æ–±—â–µ–Ω–∏–π
                # –ï—Å–ª–∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω—ã–π, —É–¥–∞–ª—è–µ–º —Å—Ç–∞—Ä—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è
                max_context_length = 20  # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–æ–æ–±—â–µ–Ω–∏–π (10 –ø–∞—Ä)
                if len(existing_context) >= max_context_length:
                    # –£–¥–∞–ª—è–µ–º —Å—Ç–∞—Ä—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è, –æ—Å—Ç–∞–≤–ª—è—è –º–µ—Å—Ç–æ –¥–ª—è –Ω–æ–≤–æ–π –ø–∞—Ä—ã
                    existing_context = existing_context[-(max_context_length-2):]
                
                # –î–æ–±–∞–≤–ª—è–µ–º –Ω–æ–≤—É—é –ø–∞—Ä—É —Å–æ–æ–±—â–µ–Ω–∏–π
                existing_context.append(message_text)
                existing_context.append(response)
                
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏—Å—Ç–æ—Ä–∏—é —á–∞—Ç–∞
                history_data = {
                    "user_id": message.from_user.id,
                    "message_text": message_text,
                    "response_text": response,
                    "model": model,
                    "context": existing_context
                }
                await save_chat_history(history_data)
                await logs_bot("debug", f"Saved context with {len(existing_context)} messages")
                
            except Exception as save_err:
                await logs_bot('error', f"Error saving chat history: {save_err}")
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ç–µ–∫—É—â–µ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
            last_messages[message.from_user.id] = (msg_old, str(response))
            return response, msg_old

    except Exception as err:
        await logs_bot('error', f"Error in AI_choice: {err}")
        error_msg = "–ò–∑–≤–∏–Ω–∏—Ç–µ, –ø—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –≤–∞—à–µ–≥–æ –∑–∞–ø—Ä–æ—Å–∞\\."
        return error_msg, msg_old

    return "–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –æ—Ç–≤–µ—Ç –æ—Ç –º–æ–¥–µ–ª–∏\\.", msg_old

openai_service = OpenAIService() 
